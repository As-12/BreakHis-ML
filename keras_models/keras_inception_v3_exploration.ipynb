{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP-CW4 Exploration Framework \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/as12production/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import matplotlib\n",
    "import keras\n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import shutil\n",
    "import fnmatch\n",
    "import pickle\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Input\n",
    "from keras.constraints import max_norm\n",
    "from keras import regularizers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import keras.initializers\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import keras.optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras setting\n",
    "K.set_image_dim_ordering('tf')  #Image dimension ordering\n",
    "\n",
    "#Random seeds\n",
    "SEED = 2082018\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#Image Settings\n",
    "IMAGE_RESIZE = (224,224)  # Image size. Process on the by data generator. Should match CNN model input. \n",
    "IMAGE_INPUT_SIZE = (224,224,3) #Image Input size to the neural network\n",
    "\n",
    "#Training Settings\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 30\n",
    "\n",
    "#Directories\n",
    "# NOTE: The labels are determined by subfolders. PNG or JPEG images only.\n",
    "TRAIN_DIR = '../TRAIN' \n",
    "VAL_DIR = '../VALID'\n",
    "TEST_DIR =  '../TEST'\n",
    "\n",
    "#Index of the class label represents numerical representation\n",
    "CLASS_LABELS = [\"Benign\", \"Malignant\"]\n",
    "NUM_CLASSES = 2\n",
    "#Checkpoints and save files\n",
    "\n",
    "#Saving every epochs that improve val accuracy\n",
    "#MODEL_CHECKPOINT_FILE=\"baseline_model-weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "# Rewriting save file for epoch that improves val accuracy\n",
    "MODEL_CHECKPOINT_FILE=\"inception3-weights.hdf5\"  \n",
    "\n",
    "#Training charts and graphics\n",
    "MODEL_TRAIN_RESULTS_FILE=\"inception3_train.pickle\"\n",
    "MODEL_ACCURACY_GRAPH_FILE=\"inception3_accuracy.pdf\"\n",
    "MODEL_LOSS_GRAPH_FILE=\"inception3_loss.pdf\"\n",
    "MODEL_EVALUATION_CM_FILE=\"inception3_CM.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildImageDataset(path, imageResize=None,shuffle=False,seed=0):\n",
    "    \"\"\"\n",
    "    Load dataset into an array. Labels are defined by folder name.\n",
    "    \"\"\"\n",
    "    filenames = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    imagePaths = sorted(list(paths.list_images(path)))\n",
    "    \n",
    "    if shuffle == True:\n",
    "        random.seed(seed)\n",
    "        random.shuffle(imagePaths)\n",
    "    \n",
    "    for imagePath in imagePaths:\n",
    "        image = cv2.imread(imagePath)\n",
    "        # Pre-process image here\n",
    "        #clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        #image = clahe.apply(image)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        if imageResize != None:\n",
    "            image = cv2.resize(image, imageResize)\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        filenames.append(imagePath)\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        labels.append(CLASS_LABELS.index(label))\n",
    "    return (np.array(data), np.array(labels), np.array(filenames))\n",
    "\n",
    "def showClassDistribution(y, labels):\n",
    "    figure = plt.figure(figsize=(10,5))\n",
    "    ax = sns.countplot(x = y)\n",
    "    ax.set_xticklabels(labels)\n",
    "    plt.show()\n",
    "\n",
    "def imageResizer(dataset, imageResize):\n",
    "    result = []\n",
    "    for image in dataset:\n",
    "        result.append(ia.imresize_single_image(image, imageResize))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_this = 0\n",
    "\n",
    "if run_this == 1:\n",
    "    LR = iaa.Sequential([iaa.Fliplr(1)])\n",
    "    UD = iaa.Sequential([iaa.Fliplr(1)])\n",
    "    RT90 = iaa.Sequential([iaa.Affine(rotate=90)])\n",
    "    RT180 = iaa.Sequential([iaa.Affine(rotate=180)])\n",
    "    RT270 = iaa.Sequential([iaa.Affine(rotate=270)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(X_train[-1])\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(X_train[1])\n",
    "ax3 = fig.add_subplot(2,2,3)\n",
    "ax3.imshow(X_train[-1])\n",
    "ax4 = fig.add_subplot(2,2,4)\n",
    "ax4.imshow(X_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End augmentaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_this = 3\n",
    "\n",
    "# Load and save\n",
    "\n",
    "if run_this == 3:\n",
    "    X_train, y_train, train_files = buildImageDataset(TRAIN_DIR,imageResize=None,seed=SEED)\n",
    "    X_valid, y_valid, valid_files = buildImageDataset(VAL_DIR,imageResize=None,seed=SEED)\n",
    "    X_test, y_test, test_files = buildImageDataset(TEST_DIR,imageResize=None,seed=SEED)\n",
    "    \n",
    "if run_this == 1:\n",
    "    X_train, y_train, train_files = buildImageDataset(TRAIN_DIR,imageResize=None,seed=SEED)\n",
    "    X_valid, y_valid, valid_files = buildImageDataset(VAL_DIR,imageResize=None,seed=SEED)\n",
    "    X_test, y_test, test_files = buildImageDataset(TEST_DIR,imageResize=None,seed=SEED)\n",
    "    \n",
    "    with open(\"X_train.pickle\", \"wb\") as output_file:\n",
    "            pickle.dump(X_train, output_file)\n",
    "\n",
    "    with open(\"y_train.pickle\", \"wb\") as output_file:\n",
    "            pickle.dump(y_train, output_file)\n",
    "\n",
    "    with open(\"X_valid.pickle\", \"wb\") as output_file:\n",
    "            pickle.dump(X_valid, output_file)\n",
    "\n",
    "    with open(\"y_valid.pickle\", \"wb\") as output_file:\n",
    "            pickle.dump(y_valid, output_file)\n",
    "    \n",
    "    with open(\"X_test.pickle\", \"wb\") as output_file:\n",
    "            pickle.dump(X_valid, output_file)\n",
    "\n",
    "    with open(\"y_test.pickle\", \"wb\") as output_file:\n",
    "            pickle.dump(y_valid, output_file)\n",
    "            \n",
    "# Quick load from saved files\n",
    "if run_this == 2:\n",
    "    X_train = pickle.load( open( \"X_train.pickle\", \"rb\" ) )\n",
    "    y_train = pickle.load( open( \"y_train.pickle\", \"rb\" ) )\n",
    "    X_valid = pickle.load( open( \"X_valid.pickle\", \"rb\" ) )\n",
    "    y_valid = pickle.load( open( \"y_valid.pickle\", \"rb\" ) )\n",
    "    X_test = pickle.load( open( \"X_test.pickle\", \"rb\" ) )\n",
    "    y_test = pickle.load( open( \"y_test.pickle\", \"rb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Magnification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\"-40\",\"-100-\",\"-200-\",\"-400-\"]\n",
    "magnifications = \"-40-\"\n",
    "\n",
    "run_this = 1\n",
    "\n",
    "if run_this == 1:\n",
    "    validDataFrame = pd.DataFrame({'label':y_valid, 'filename':valid_files})\n",
    "    trainDataFrame = pd.DataFrame({'label':y_train, 'filename':train_files})\n",
    "    testDataFrame = pd.DataFrame({'label':y_test, 'filename':test_files})\n",
    "    index = [i for i,item in enumerate(trainDataFrame[\"filename\"]) if magnifications in item]\n",
    "    X_train = X_train[index]\n",
    "    y_train = y_train[index]\n",
    "    train_files = train_files[index]\n",
    "    \n",
    "    index = [i for i,item in enumerate(validDataFrame[\"filename\"]) if magnifications in item]\n",
    "    X_valid = X_valid[index]\n",
    "    y_valid = y_valid[index]\n",
    "    valid_files = valid_files[index]\n",
    "    \n",
    "    index = [i for i,item in enumerate(testDataFrame[\"filename\"]) if magnifications in item]\n",
    "    X_test = X_test[index]\n",
    "    y_test = y_test[index]\n",
    "    test_files = test_files[index]\n",
    "    \n",
    "    with open(\"Train set \" + magnifications + \".txt\", 'w') as the_file:\n",
    "        the_file.writelines(train_files)\n",
    "        \n",
    "    with open(\"Valid set \" + magnifications + \".txt\", 'w') as the_file:\n",
    "        the_file.writelines(valid_files)\n",
    "        \n",
    "    with open(\"Test set \" + magnifications + \".txt\", 'w') as the_file:\n",
    "        the_file.writelines(test_files)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images_aug1 = LR.augment_images(X_train)\n",
    "images_aug2 = UD.augment_images(X_train)\n",
    "images_aug3 = RT90.augment_images(X_train)\n",
    "images_aug4 = RT180.augment_images(X_train)\n",
    "images_aug5 = RT270.augment_images(X_train)\n",
    "X_train = np.vstack((np.vstack((\n",
    "                     np.vstack((\n",
    "                         np.vstack((\n",
    "                             np.vstack((images_aug1,images_aug2)),images_aug3)),images_aug4)),images_aug5)),X_train))\n",
    "y_temp = np.array([])\n",
    "for i in range(6):\n",
    "    y_temp = np.concatenate((y_temp,y_train))\n",
    "y_train = y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1368, 460, 700, 3)\n",
      "(1368,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataFrame = pd.DataFrame({'label':y_train, 'filename':train_files})\n",
    "print(\"There are {} items in training set.\".format(len(y_train) ))\n",
    "trainDataFrame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showClassDistribution(y_train, CLASS_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validDataFrame = pd.DataFrame({'label':y_valid, 'filename':valid_files})\n",
    "print(\"There are {} items in validation set.\".format(len(y_valid) ))\n",
    "validDataFrame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showClassDistribution(y_valid, CLASS_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataFrame = pd.DataFrame({'label':y_test, 'filename':test_files})\n",
    "print(\"There are {} items in test set.\".format(len(y_test) ))\n",
    "testDataFrame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageStandardizer:\n",
    "    \"\"\"\n",
    "    This class standardizer image to zero mean and unit variance\n",
    "    Normalization is done for each image channel\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=1e-7):\n",
    "        self._mean = 0\n",
    "        self._std = 0\n",
    "        self._ready = False\n",
    "        self._epsilon = eps # To prevent divide by zero\n",
    "    \n",
    "    def fit(self, train):\n",
    "        self._mean = np.mean(train,axis=(0, 1, 2, 3))\n",
    "        self._std = np.std(train, axis=(0, 1, 2, 3))\n",
    "        self._ready = True\n",
    "    \n",
    "    def transform(self, data):\n",
    "        assert self._ready == True, \"ImageStandardizer must be initialized before use. Use fit() to initialize.\"\n",
    "        return (data - self._mean)/(self._std + self._epsilon)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_this = 0\n",
    "\n",
    "if run_this == 1:\n",
    "    Standardizer = ImageStandardizer()\n",
    "    ImageStandardizer.fit(X_train)\n",
    "    X_train = ImageStandardizer.transform(X_train)\n",
    "    X_valid = ImageStandardizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255.0\n",
    "X_valid /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation / Data Generator\n",
    "\n",
    "See Keras documentation for details https://faroit.github.io/keras-docs/1.1.0/preprocessing/image/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No augmentation on baseline. Only normalize to [0,1.0] scale.\n",
    "trainDataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "validDataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "testDataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "#  data augmentation\n",
    "#trainDataGenerator = ImageDataGenerator(\n",
    "#            rescale=1./255,\n",
    "#            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#            samplewise_center=False,  # set each sample mean to 0\n",
    "#          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#           samplewise_std_normalization=False,  # divide each input by its std\n",
    "#           zca_whitening=False,  # apply ZCA whitening\n",
    "#           rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#            horizontal_flip=True,  # randomly flip images\n",
    "#            vertical_flip=False)  # randomly flip images\n",
    " #(std, mean, and principal components if ZCA whitening is applied).\n",
    "\n",
    "trainDataGenerator.fit(X_train)\n",
    "validDataGenerator.fit(X_valid)\n",
    "testDataGenerator.fit(X_test)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_valid = keras.utils.to_categorical(y_valid)\n",
    "y_test = keras.utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split images into regions\n",
    "\n",
    "def splitImage(image, n_split, resize):\n",
    "    \"\"\"\n",
    "    Takes a numpy image matrix, and split them based into nxn matrix\n",
    "    return numpy matrix (regions, rows, columns, channel)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.misc import imresize \n",
    "    #Calculate region width and height\n",
    "    block_r = int(np.floor(image.shape[0] / n_split))\n",
    "    block_c = int(np.floor(image.shape[1] / n_split))\n",
    "    \n",
    "    result = []\n",
    "    #Split the image based on block_r and block_c, and append it to result array\n",
    "    row = 0\n",
    "    for _ in range(0,n_split-1):\n",
    "        col = 0\n",
    "        start_r = row  * block_r\n",
    "        for _ in range(0,n_split-1):\n",
    "            start_c = col  * block_c\n",
    "            result.append(imresize(image[start_r:start_r + block_r, start_c:start_c + block_c,:],resize))\n",
    "            col += 1\n",
    "        #Some images may not divide evenly, so use the remaining pixels on the last patch\n",
    "        start_c = col * block_c\n",
    "        result.append(imresize(image[start_r:start_r + block_r, start_c:,:],resize))\n",
    "        row += 1\n",
    "    #Some images may not divide evenly, so use the remaining pixels on the last patch\n",
    "    start_r = row  * block_r\n",
    "    col = 0\n",
    "    for _ in range(0,n_split-1):\n",
    "        start_c = col  * block_c\n",
    "        result.append(imresize(image[start_r:, start_c:start_c + block_c,:],resize))\n",
    "        col += 1\n",
    "    #Some images may not divide evenly, so use the remaining pixels on the last patch\n",
    "    start_c = col * block_c\n",
    "    result.append(imresize(image[start_r:, start_c:, :],resize))\n",
    "    return np.array(result).astype('float')/255.0\n",
    "\n",
    "\n",
    "def regionScore(image, threshold=(0.5,0.5,0.5)):\n",
    "    \"\"\"\n",
    "    Takes a numpy image matrix (row,col,channels) and associated threshold value for each channels.\n",
    "    Return a copy of matrix with anything greater than or equal to threshold sets to \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def color_threshold(img, th):\n",
    "        \"\"\"\n",
    "        Takes a numpy image matrix (row,col,channels) and associated threshold value for each channel. \n",
    "        Return a copy of matrix with anything greater than or equal to threshold sets to one and zero for everything else.\n",
    "        \"\"\"\n",
    "        assert img.shape[2] == len(th), \"number of channels must be equal to number of threshold\"\n",
    "        result = np.copy(img)\n",
    "        for channel, value in enumerate(th):\n",
    "            low_values_flags = result[:,:,channel] < value  # Where values are low\n",
    "            high_values_flags = result[:,:,channel] >= value  # Where values are low\n",
    "            result[low_values_flags,channel] = 1  # All low values set to 0\n",
    "            result[high_values_flags,channel] = 0  # All low values set to 0\n",
    "        return result\n",
    "\n",
    "    \n",
    "    return np.sum(color_threshold(image, threshold))\n",
    "\n",
    "def isRegionOfInterest(image, threshold=(0.5,0.5,0.5), perecent_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Takes a numpy image matrix (row,col,channels) and associated threshold value for each channels.\n",
    "    Return a copy of matrix with anything greater than or equal to threshold sets to \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    def color_threshold(img, th):\n",
    "        \"\"\"\n",
    "        Takes a numpy image matrix (row,col,channels) and associated threshold value for each channel. \n",
    "        Return a copy of matrix with anything greater than or equal to threshold sets to one and zero for everything else.\n",
    "        \"\"\"\n",
    "        assert img.shape[2] == len(th), \"number of channels must be equal to number of threshold\"\n",
    "        result = np.copy(img)\n",
    "        for channel, value in enumerate(th):\n",
    "            low_values_flags = result[:,:,channel] < value  # Where values are low\n",
    "            high_values_flags = result[:,:,channel] >= value  # Where values are low\n",
    "            result[low_values_flags,channel] = 1  # All low values set to 0\n",
    "            result[high_values_flags,channel] = 0  # All low values set to 0\n",
    "        return result\n",
    "\n",
    "    \n",
    "    if ( float(np.sum(color_threshold(image, threshold))) / totalImageSize(image)) > float(perecent_threshold):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def segmentCell2(set_of_images, resize):\n",
    "    cell = []\n",
    "    for index, image in enumerate(set_of_images):\n",
    "        for patch in splitImage(image,6,resize):\n",
    "            if (isRegionOfInterest(patch, threshold=(0.5,0.5,0.5), perecent_threshold=0.20)):\n",
    "                cell.append(patch)\n",
    "    return np.array(cell)\n",
    "\n",
    "def segmentCell(set_of_images, resize):\n",
    "    cell = []\n",
    "    for index, image in enumerate(set_of_images):\n",
    "        score = []\n",
    "        patches = []\n",
    "        for patch in splitImage(image,6,resize):\n",
    "            score.append(regionScore(patch, threshold=(0.5,0.5,0.5)))\n",
    "            patches.append(patch)\n",
    "        # Non-Maximum suppression\n",
    "        score = np.array(score)\n",
    "        patches = np.array(patches)\n",
    "        cell.append(patches[np.argmax(score)])\n",
    "    return np.array(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/as12production/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/home/as12production/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/home/as12production/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/home/as12production/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3990a7408d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_RESIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_vl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_RESIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-80962f4fb835>\u001b[0m in \u001b[0;36msegmentCell\u001b[0;34m(set_of_images, resize)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# Non-Maximum suppression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_tr = segmentCell(X_train, IMAGE_RESIZE)\n",
    "X_vl = segmentCell(X_valid, IMAGE_RESIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_tr.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_valid = keras.utils.to_categorical(y_valid)\n",
    "X_train = X_tr\n",
    "X_valid = X_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5\n",
    "for i in range(num):\n",
    "    plt.imshow(X_train[i]*255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Building Models\n",
    "def InceptionNet(verbose=False):\n",
    "    #https://keras.io/applications/#inceptionv3\n",
    "    #Use Inception 3 without the last layer.\n",
    "    #Replace last layer with 1 sigmoid for binary classification\n",
    "    sgd = SGD(lr=0.01, momentum=0.9,nesterov=False)\n",
    "    model = keras.applications.inception_v3.InceptionV3(include_top=False,\n",
    "                                                        weights='imagenet',  #Pre-train on ImageNet \n",
    "                                                        input_tensor=Input(shape=IMAGE_INPUT_SIZE),\n",
    "                                                        input_shape=None,\n",
    "                                                        pooling='avg',\n",
    "                                                        classes=NUM_CLASSES)\n",
    "    final = Model(input=model.input,output=Dense(NUM_CLASSES, activation='softmax')(model.output))\n",
    "    if verbose == True:\n",
    "        final.summary()\n",
    "    final.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])    \n",
    "    return final\n",
    "\n",
    "model = InceptionNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting checkpoint options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(MODEL_CHECKPOINT_FILE, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading weights\n",
    "\n",
    "In case issue with training / crash. Run this to load the weights into model. You can either train the model or use it for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_this = 0\n",
    "\n",
    "#Specify checkpoint file here\n",
    "CHECKPOINT_FILE = MODEL_CHECKPOINT_FILE\n",
    "\n",
    "###############################################\n",
    "if run_this == 1:\n",
    "    model.load_weights(CHECKPOINT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training W/O Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_this = 1\n",
    "\n",
    "if run_this == 1:\n",
    "    #Train models\n",
    "   \n",
    "    history = model.fit(x=X_train,y=y_train,\n",
    "                        validation_data=(X_valid,y_valid),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs = EPOCH,\n",
    "                       callbacks = callbacks_list)\n",
    "    \n",
    "    #Saving training result\n",
    "    with open(MODEL_TRAIN_RESULTS_FILE, \"wb\") as output_file:\n",
    "        pickle.dump(history.history, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training w/ Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_this = 0\n",
    "\n",
    "if run_this == 1:\n",
    "    #Train models\n",
    "    history = model.fit_generator(\n",
    "        trainDataGenerator.flow(X_train, y_train),\n",
    "        epochs = EPOCH,\n",
    "        steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
    "        validation_data=validDataGenerator.flow(X_valid, y_valid),\n",
    "        callbacks = callbacks_list)\n",
    "    \n",
    "    #Saving training result\n",
    "    with open(MODEL_TRAIN_RESULTS_FILE, \"wb\") as output_file:\n",
    "        pickle.dump(history.history, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Visualizing Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_this = 1\n",
    "\n",
    "if run_this == 1:\n",
    "    with open(MODEL_TRAIN_RESULTS_FILE, \"rb\") as input_file:\n",
    "        history = pickle.load(input_file)\n",
    "    plt.style.use('ggplot')\n",
    "    accuracy_plot = plt.figure(figsize=(15,10))\n",
    "    for k in ['val_acc', 'acc']:\n",
    "        data = np.array(history[k])\n",
    "        plt.plot(data)\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch Number')\n",
    "    plt.legend(['acc(valid)', 'acc(train)'], loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    loss_plot = plt.figure(figsize=(15,10))\n",
    "    for k in ['loss', 'val_loss']:\n",
    "        data = np.array(history[k])\n",
    "        plt.plot(data)\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Error (Log Loss)')\n",
    "    plt.xlabel('Epoch Number')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['error(train)', 'error(valid)'], loc='upper left')\n",
    "    plt.show()\n",
    "    #Save visualization data\n",
    "    print(\"Val Acc: \",np.max(np.array(history['val_acc'])))\n",
    "    print(\"Train Acc: \", np.max(np.array(history['acc'])))\n",
    "    print(\"Val Err: \",np.max(np.array(history['val_loss'])))\n",
    "    print(\"Train Err: \", np.max(np.array(history['loss'])))\n",
    "    accuracy_plot.savefig(MODEL_ACCURACY_GRAPH_FILE, bbox_inches='tight')\n",
    "    loss_plot.savefig(MODEL_LOSS_GRAPH_FILE, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set Confusion Matrix\n",
    "\n",
    "#### Note: \n",
    "The labels are hard coded and might not represent the actual label as automatically created by DataGenerator. So switch it around until we figure out the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_this = 1\n",
    "\n",
    "\n",
    "    \n",
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    plot = plt.figure()\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    return plot\n",
    "    \n",
    "    \n",
    "if run_this == 1:\n",
    "    #model.load_weights(MODEL_CHECKPOINT_FILE)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    cm = confusion_matrix(np.argmax(y_valid,axis=1), np.argmax(np.rint(y_pred),axis=1))\n",
    "    cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "    plot = plot_confusion_matrix(cm_norm, classes=CLASS_LABELS)\n",
    "    plot.savefig(MODEL_EVALUATION_CM_FILE, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "Scalar test loss (if the model has no metrics) or list of scalars (if the model computes other metrics). The attribute model.metrics_names will give you the display labels for the scalar outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_this = 1\n",
    "\n",
    "if run_this == 1:\n",
    "    scores = model.evaluate(X_test,y_test)\n",
    "    print(scores)\n",
    "    print(model.metrics_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_this = 1\n",
    "if run_this == 1:\n",
    "    scores = model.evaluate(X_valid,y_valid)\n",
    "    print(scores)\n",
    "    print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = InceptionNet()\n",
    "model2.load_weights(MODEL_CHECKPOINT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_this == 1:\n",
    "    scores = model2.evaluate(X_valid,y_valid)\n",
    "    print(scores)\n",
    "    print(model2.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_this == 1:\n",
    "    #model.load_weights(MODEL_CHECKPOINT_FILE)\n",
    "    y_pred = model2.predict(X_valid)\n",
    "    cm = confusion_matrix(np.argmax(y_valid,axis=1), np.argmax(np.rint(y_pred),axis=1))\n",
    "    cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "    plot = plot_confusion_matrix(cm_norm, classes=CLASS_LABELS)\n",
    "    plot.savefig(MODEL_EVALUATION_CM_FILE, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
